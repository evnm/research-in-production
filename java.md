# Java

_The original version of this list was collated by
[Alex Denisov](https://github.com/AlexDenisov) on
[his blog](https://lowlevelbits.org/java-papers/)._

## Preceding research used

### [A Practical Minimal Perfect Hashing Method](http://homepages.dcc.ufmg.br/~nivio/papers/wea05.pdf)

_Fabiano C. Botelho, Yoshiharu Kohayakawa, and Nivio Ziviani_

__Abstract.__ We propose a novel algorithm based on random graphs to
construct minimal perfect hash functions h. For a set of n keys, our
algorithm outputs `h` in expected time `O(n)`. The evaluation of
`h(x)` requires two memory accesses for any key `x` and the
description of `h` takes up `1.15n` words. This improves the space
requirement to 55% of a previous minimal perfect hashing scheme due to
Czech, Havas and Majewski. A simple heuristic further reduces the
space requirement to `0.93n` words, at the expense of a slightly worse
constant in the time complexity. Large scale experimental results are
presented.

### [Correct and Efficient Work-Stealing for Weak Memory Models](http://www.di.ens.fr/~zappa/readings/ppopp13.pdf)

__Abstract.__ Chase and Lev’s concurrent deque is a key data structure
in shared-memory parallel programming and plays an essential role in
work-stealing schedulers. We provide the first correctness proof of an
optimized implementation of Chase and Lev’s deque on top of the POWER
and ARM architectures: these provide very relaxed memory models, which
we exploit to improve performance but considerably complicate the
reasoning. We also study an optimized x86 and a portable C11
implementation, conducting systematic experiments to evaluate the
impact of memory barrier optimizations. Our results demonstrate the
benefits of hand tuning the deque code when running on top of relaxed
memory models.

### [Digital Signature Standard (DSS)](http://csrc.nist.gov/publications/fips/fips186-3/fips_186-3.pdf)

_Information Technology Laboratory, National Institute of Standards and Technology_

__Abstract.__ This Standard specifies a suite of algorithms that can
be used to generate a digital signature. Digital signatures are used
to detect unauthorized modifications to data and to authenticate the
identity of the signatory. In addition, the recipient of signed data
can use a digital signature as evidence in demonstrating to a third
party that the signature was, in fact, generated by the claimed
signatory. This is known as non-repudiation, since the signatory
cannot easily repudiate the signature at a later time.

### [Effective Synchronization on Linux/NUMA Systems](https://web.archive.org/web/20060707150749/http://lameter.com/gelato2005.pdf)

_Christoph Lameter_

__Abstract.__ Effective locking is necessary for satisfactory
performance on large Itanium based NUMA systems. Synchronization of
parallel executing streams on NUMA machines is currently realized in
the Linux kernel through a variety of mechanisms which include atomic
operations, locking and ordering of memory accesses. Various
synchronization methods may also be combined in order to increase
performance. The talk presents the realization of basic
synchronization in Linux on Itanium and then investigates more complex
locking schemes. The current Linux locking mechanisms rely heavily on
a simple spinlock implementation that may be fitting for systems of up
to 8 processors. However, spinlocks cause excessive cache line
bouncing if more processors are contending for a lock. Some approaches
that have so far been made to solve the contention issue are presented
and it is then suggested to use an implementation for Linux of the
approach first proposed by Zoran Radovic which he called “Hierarchical
Backoff Locks”.

### [Mirrors: Design Principles for Meta-level Facilities of Object-Oriented Programming Languages](http://bracha.org/mirrors.pdf)

_Gilad Bracha and David Ungar_

__Abstract.__ We identify three design principles for reflection and
metaprogramming facilities in object oriented programming
languages. Encapsulation: meta-level facilities must encapsulate their
implementation. Stratification: meta-level facilities must be
separated from base-level functionality. Ontological correspondence:
the ontology of meta-level facilities should correspond to the
ontology of the language they manipulate. Traditional/mainstream
reflective architectures do not follow these precepts. In contrast,
reflective APIs built around the concept of mirrors are characterized
by adherence to these three principles. Consequently, mirror-based
architectures have significant advantages with respect to
distribution, deployment and general purpose metaprogramming.

### [Nonblocking Concurrent Data Structures with Condition Synchronization](https://web.archive.org/web/20110206165336/http://www.cs.rice.edu/~wns1/papers/2004-DISC-DDS.pdf)

_William N. Scherer III and Michael L. Scott_

__Abstract.__ We apply the classic theory of linearizability to
operations that must wait for some other thread to establish a
precondition. We model such an operation as a request and a follow-up,
each with its own linearization point. Linearization of the request
marks the point at which a thread’s wishes become visible to its
peers; linearization of the follow-up marks the point at which the
request is fulfilled and the operation takes effect. By placing both
linearization points within the purview of object semantics, we can
specify not only the effects of operations, but also the order in
which pending requests should be fulfilled. We use the term dual data
structure to describe a concurrent object implementation that may hold
both data and reservations (registered requests). By reasoning
separately about a request, its successful follow-up, and the period
in-between, we obtain meaningful definitions of nonblocking dual data
structures. As concrete examples, we present lock-free dualstacks and
dualqueues, and experimentally compare their performance with that of
lock-based and nonblocking alternatives.

### [Recommendation for Block Cipher Modes of Operation: Galois/Counter Mode (GCM) and GMAC](http://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-38d.pdf)

_Morris Dworkin_

__Abstract.__ This Recommendation specifies the Galois/Counter Mode
(GCM), an algorithm for authenticated encryption with associated data,
and its specialization, GMAC, for generating a message authentication
code (MAC) on data that is not encrypted. GCM and GMAC are modes of
operation for an underlying approved symmetric key block cipher.

### [Recommendation for Random Number Generation Using Deterministic Random Bit Generators](http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-90Ar1.pdf)

_Elaine Barker and John Kelsey_

__Abstract.__ This Recommendation specifies mechanisms for the
generation of random bits using deterministic methods. The methods
provided are based on either hash functions or block cipher
algorithms.

### [Security requirements for cryptographic modules](http://csrc.nist.gov/publications/fips/fips140-2/fips1402.pdf)

_Information Technology Laboratory, National Institute of Standards and Technology_

__Abstract__. The selective application of technological and related
procedural safeguards is an important responsibility of every Federal
organization in providing adequate security in its computer and
telecommunication systems. This publication provides a standard that
will be used by Federal organizations when these organizations specify
that cryptographic-based security systems are to be used to provide
protection for sensitive or valuable data. Protection of a
cryptographic module within a security system is necessary to maintain
the confidentiality and integrity of the information protected by the
module. This standard specifies the security requirements that will be
satisfied by a cryptographic module. The standard provides four
increasing, qualitative levels of security intended to cover a wide
range of potential applications and environments. The security
requirements cover areas related to the secure design and
implementation of a cryptographic module. These areas include
cryptographic module specification; cryptographic module ports and
interfaces; roles, services, and authentication; finite state model;
physical security; operational environment; cryptographic key
management; electromagnetic interference/electromagnetic compatibility
(EMI/EMC); self-tests; design assurance; and mitigation of other
attacks.

### [Simple, Fast, and Practical Non-Blocking and Blocking Concurrent Queue Algorithms](http://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf)

_Maged M. Michael and Michael L. Scott_

__Abstract.__ Drawing ideas from previous authors, we present a new
non-blocking concurrent queue algorithm and a new two-lock queue
algorithm in which one enqueue and one dequeue can proceed
concurrently. Both algorithms are simple, fast, and practical; we were
surprised not to find them in the literature. Experiments on a 12-node
SGI Challenge multiprocessor indicate that the new non-blocking queue
consistently outperforms the best known alternatives; it is the clear
algorithm of choice for machines that provide a universal atomic
primitive (e.g. compare_and_swap or
load_linked/store_conditional). The two-lock concurrent queue
outperforms a single lock when several processes are competing
simultaneously for access; it appears to be the algorithm of choice
for busy queues on machines with non-universal atomic primitives
(e.g. test_and_set). Since much of the motivation for non-blocking
algorithms is rooted in their immunity to large, unpredictable delays
in process execution, we report experimental results both for systems
with dedicated processors and for systems with several processes
multiprogrammed on each processor.

### [The Galois/Counter Mode of Operation (GCM)](http://csrc.nist.gov/groups/ST/toolkit/BCM/documents/proposedmodes/gcm/gcm-revised-spec.pdf)

_David A. McGrew and John Viega_

__Abstract.__ Galois/Counter Mode (GCM) is a block cipher mode of
operation that uses universal hashing over a binary Galois field to
provide authenticated encryption. It can be implemented in hardware to
achieve high speeds with low cost and low latency. Software
implementations can achieve excellent performance by using
table-driven field operations. It uses mechanisms that are supported
by a well-understood theoretical foundation, and its security follows
from a single reasonable assumption about the security of the block
cipher.

### [Triple Handshakes and Cookie Cutters: Breaking and Fixing Authentication over TLS](https://web.archive.org/web/20160304042237/https://secure-resumption.com/tlsauth.pdf)

_Karthikeyan Bhargavan, Antoine Delignat-Lavaud, Cédric Fournet,
Alfredo Pironti, and Pierre-Yves Strub_

__Abstract.__ TLS was designed as a transparent channel abstraction to
allow developers with no cryptographic expertise to protect their
application against attackers that may control some clients, some
servers, and may have the capability to tamper with network
connections. However, the security guarantees of TLS fall short of
those of a secure channel, leading to a variety of attacks. We show
how some widespread false beliefs about these guarantees can be
exploited to attack popular applications and defeat several standard
authentication methods that rely too naively on TLS. We present new
client impersonation attacks against TLS renegotiations, wireless
networks, challenge-response protocols, and channel-bound cookies. Our
attacks exploit combinations of RSA and Diffie-Hellman key exchange,
session resumption, and renegotiation to bypass many recent
countermeasures. We also demonstrate new ways to exploit known
weaknesses of HTTP over TLS. We investigate the root causes for these
attacks and propose new countermeasures. At the protocol level, we
design and implement two new TLS extensions that strengthen the
authentication guarantees of the handshake. At the application level,
we develop an exemplary HTTPS client library that implements several
mitigations, on top of a previously verified TLS implementation, and
verify that their composition provides strong, simple application
security.

### [Worst Cases for Correct Rounding of the Elementary Functions in Double Precision](http://perso.ens-lyon.fr/jean-michel.muller/TMDworstcases.pdf)

_Vincent Lefèvre and Jean-Michel Muller_

__Abstract.__ We give the results of our search for the worst cases
for correct rounding of the major elementary functions in double
precision floating-point arithmetic. These results allow the design of
reasonably fast routines that will compute these functions with
correct rounding, at least in some interval, for any of the four
rounding modes specified by the IEEE-754 standard. They will also
allow one to easily test libraries that are claimed to provide
correctly rounded functions.

### [Optimizing Dynamically-Typed Object-Oriented Languages With Polymorphic Inline Caches](http://www.cs.ucsb.edu/~urs/oocsb/papers/ecoop91.pdf)

_Urs Hölzle, Craig Chambers, and David Ungar_

__Abstract.__ Polymorphic inline caches (PICs) provide a new way to
reduce the overhead of polymorphic message sends by extending inline
caches to include more than one cached lookup result per call
site. For a set of typical object-oriented SELF programs, PICs achieve
a median speedup of 11%.  As an important side effect, PICs collect
type information by recording all of the receiver types actually used
at a given call site. The compiler can exploit this type information
to generate better code when recompiling a method. An experimental
version of such a system achieves a median speedup of 27% for our set
of SELF programs, reducing the number of non-inlined message sends by
a factor of two.  Implementations of dynamically-typed object-oriented
languages have been limited by the paucity of type information
available to the compiler. The abundance of the type information
provided by PICs suggests a new compilation approach for these
languages, adaptive compilation. Such compilers may succeed in
generating very efficient code for the time-critical parts of a
program without incurring distracting compilation pauses.

### [Optimizing Dynamically-Dispatched Calls with Run-Time Type Feedback](http://www.cs.ucsb.edu/~urs/oocsb/papers/pldi94.pdf)

_Urs Hölzle and David Ungar_

__Abstract.__ Object-oriented programs are difficult to optimize
because they execute many dynamically-dispatched calls. These calls
cannot easily be eliminated because the compiler does not know which
callee will be invoked at runtime. We have developed a simple
technique that feeds back type information from the runtime system to
the compiler. With this type feedback, the compiler can inline any
dynamically-dispatched call. Our compiler drastically reduces the call
frequency of a suite of large SELF applications (by a factor of 3.6)
and improves performance by a factor of 1.7. We believe that type
feedback could significantly reduce call frequencies and improve
performance for most other object-oriented languages (statically-typed
or not) as well as for languages with type-dependent operations such
as generic arithmetic.

## Research produced

### [An optimistic approach to lock-free FIFO queues](http://people.csail.mit.edu/edya/publications/OptimisticFIFOQueue-journal.pdf)

_Edya Ladan-Mozes and Nir Shavit_

__Abstract.__ First-in-first-out (FIFO) queues are among the most
fundamental and highly studied concurrent data structures. The most
effective and practical dynamic-memory concurrent queue implementation
in the literature is the lock-free FIFO queue algorithm of Michael and
Scott, included in the standard Java™ Concurrency Package. This work
presents a new dynamic-memory concurrent lock-free FIFO queue
algorithm that in a variety of circumstances performs better than the
Michael and Scott queue. The key idea behind our new algorithm is a
novel way of replacing the singly-linked list of Michael and Scott,
whose pointers are inserted using a costly compare-and-swap (CAS)
operation, by an “optimistic” doubly-linked list whose pointers are
updated using a simple store, yet can be “fixed” if a bad ordering of
events causes them to be inconsistent. We believe it is the first
example of such an “optimistic” approach being applied to a real world
data structure.

### [Implementing Fast Java™ Monitors with Relaxed-Locks](http://www.usenix.org/events/jvm01/full_papers/dice/dice.pdf)

_David Dice_

__Abstract.__ The Java™ Programming Language permits synchronization
operations (lock, unlock, wait, notify) on any object. Synchronization
is very common in applications and is endemic in the library code upon
which applications depend. It is therefore critical that a monitor
implementation be both space-efficient and time-efficient. We present
a locking protocol, the Relaxed-Lock, that satisfies those
requirements. The Relaxed-Lock is reasonably compact, using only one
machine word in the object header. It is fast, requiring in the
uncontested case only one atomic compare-and-swap to lock a monitor
and no atomic instructions to release a monitor. The Relaxed-Lock
protocol is unique in that it admits a benign data race in the monitor
unlock path (hence its name) but detects and recovers from the race
and thus maintains correct mutual exclusion. We also introduce
speculative deflation, a mechanism for releasing a monitor when it is
no longer needed

### [OpenJDK’s java.utils.Collection.sort() is broken: The good, the bad and the worst case](http://envisage-project.eu/wp-content/uploads/2015/02/sorting.pdf)

_Stijn de Gouw, Jurriaan Rot, Frank S. de Boer, Richard Bubel, and Reiner Hähnle_

__Abstract.__ We investigate the correctness of TimSort, which is the
main sorting algorithm provided by the Java standard library. The goal
is functional verification with mechanical proofs. During our
verification attempt we discovered a bug which causes the
implementation to crash. We characterize the conditions under which
the bug occurs, and from this we derive a bug-free version that does
not compromise the performance. We formally specify the new version
and mechanically verify the absence of this bug with KeY, a
state-of-the-art verification tool for Java.

### [Scalable Synchronous Queues](http://www.cs.rochester.edu/u/scott/papers/2009_Scherer_CACM_SSQ.pdf)

_William N. Scherer III, Doug Lea, and Michael L. Scott_

__Abstract.__ In a thread-safe concurrent queue, consumers typically
wait for producers to make data available. In a synchronous queue,
producers similarly wait for consumers to take the data. We present
two new nonblocking, contention-free synchronous queues that achieve
high performance through a form of dualism: The underlying data
structure may hold both data and, symmetrically, requests. We present
performance results on 16-processor SPARC and 4-processor Opteron
machines. We compare our algorithms to commonly used alternatives from
the literature and from the Java SE 5.0 class
java.util.concurrent.SynchronousQueue both directly in synthetic
microbenchmarks and indirectly as the core of Java’s
ThreadPoolExecutor mechanism. Our new algorithms consistently
outperform the Java SE 5.0 SynchronousQueue by factors of three in
unfair mode and 14 in fair mode; this translates to factors of two and
ten for the ThreadPoolExecutor. Our synchronous queues have been
adopted for inclusion in Java 6.

### [A Simple Graph-Based Intermediate Representation](http://www.oracle.com/technetwork/java/javase/tech/c2-ir95-150110.pdf)

_Cliff Click and Michael Paleczny_

__Abstract.__ We present a graph-based intermediate representation
(IR) with simple semantics and a low-memory-cost C++
implementation. The IR uses a directed graph with la-
beled vertices and ordered inputs but unordered outputs.
Vertices are labeled with opcodes, edges are unlabeled.
We represent the CFG and basic blocks with the same
vertex and edge structures. Each opcode is defined by a
C++ class that encapsulates opcode-specific data and be-
havior. We use inheritance to abstract common opcode
behavior, allowing new opcodes to be easily defined from
old ones. The resulting IR is simple, fast and easy to use.

### [Linear Scan Register Allocation on SSA Form](http://www.christianwimmer.at/Publications/Wimmer10a/Wimmer10a.pdf)

_Christian Wimmer and Michael Franz_

__Abstract.__ The linear scan algorithm for register allocation provides a good
register assignment with a low compilation overhead and is thus
frequently used for just-in-time compilers. Although most of these
compilers use static single assignment (SSA) form, the algorithm
has not yet been applied on SSA form, i.e., SSA form is usually
deconstructed before register allocation. However, the structural
properties of SSA form can be used to simplify the algorithm.
With only one definition per variable, lifetime intervals (the
main data structure) can be constructed without data flow analy-
sis. During allocation, some tests of interval intersection can be
skipped because SSA form guarantees non-intersection. Finally,
deconstruction of SSA form after register allocation can be inte-
grated into the resolution phase of the register allocator without
much additional code.
We modified the linear scan register allocator of the Java
HotSpot TM client compiler so that it operates on SSA form. The
evaluation shows that our simpler and faster version generates
equally good or slightly better machine code.

### [Parallel Garbage Collection for Shared Memory Multiprocessors](http://people.csail.mit.edu/shanir/publications/dfsz2001.pdf)

_Christine H. Flood, David Detlefs, Nir Shavit, and Xiolan Zhang_

__Abstract.__ We present a multiprocessor “stop-the-world”
garbage collection framework that provides multiple
forms of load balancing. Our parallel collectors
use this framework to balance the work of root scanning,
using static overpartitioning, and also to balance
the work of tracing the object graph, using a
form of dynamic load balancing called work stealing.
We describe two collectors written using this
framework: pSemispaces, a parallel semispace collector,
and pMarkcompact, a parallel markcompact
collector.

### [A Generational Mostly-concurrent Garbage Collector](http://www.cs.ucsb.edu/~ckrintz/racelab/gc/papers/detlefs-generational.pdf)

_Tony Printezis and David Detlefs_

__Abstract.__ This paper reports our experiences with a
mostly-concurrent incremental garbage collector, implemented in the
context of a high performance virtual machine for the Java™
programming language. The garbage collector is based on the “mostly
parallel” collection algorithm of Boehm et al., and can be used as the
old generation of a generational memory system. It overloads effi-
cient write-barrier code already generated to support generational
garbage collection to also identify objects that were modified during
concurrent marking. These objects must be rescanned to ensure that the
concurrent marking phase marks all live objects. This algorithm
minimises maximum garbage collection pause times, while having only a
small impact on the average garbage collection pause time and overall
execution time. We support our claims with experimental results, for
both a synthetic benchmark and real programs.

### [Garbage-First Garbage Collection](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.6386&rep=rep1&type=pdf)

_David Detlefs, Christine Flood, Steve Heller, and Tony Printezis_

__Abstract.__ Garbage-First is a server-style garbage collector,
targeted for multi-processors with large memories, that meets a soft
real-time goal with high probability, while achieving high
throughput. Whole-heap operations, such as global marking, are
performed concurrently with mutation, to prevent interruptions
proportional to heap or live-data size. Concurrent marking both
provides collection ”completeness ” and identifies regions ripe for
reclamation via compacting evacuation. This evacuation is performed in
parallel on multiprocessors, to increase throughput.

### [C4: The Continuously Concurrent Compacting Collector](http://www.azulsystems.com/sites/default/files/images/c4_paper_acm.pdf)

_Gil Tene, Balaji Iyengar, and Michael Wolf_

__Abstract.__ C4, the Continuously Concurrent Compacting Collector, an
up- dated generational form of the Pauseless GC Algorithm, is in-
troduced and described, along with details of its implementation on
modern X86 hardware. It uses a read barrier to support concur- rent
compaction, concurrent remapping, and concurrent incremen- tal update
tracing. C4 differentiates itself from other generational garbage
collectors by supporting simultaneous-generational con- currency: the
different generations are collected using concurrent (non
stop-the-world) mechanisms that can be simultaneously and
independently active. C4 is able to continuously perform concur- rent
young generation collections, even during long periods of con- current
full heap collection, allowing C4 to sustain high allocation rates and
maintain the efficiency typical to generational collectors, without
sacrificing response times or reverting to stop-the-world
operation. Azul systems has been shipping a commercial imple-
mentation of the Pauseless GC mechanism, since 2005. Three suc-
cessive generations of Azul’s Vega series systems relied on custom
multi-core processors and a custom OS kernel to deliver both the scale
and features needed to support Pauseless GC. In 2010, Azul released
its first software-only commercial implementation of C4 for modern
commodity X86 hardware, using Linux kernel enhance- ments to support
the required feature set. We discuss implementa- tion details of C4 on
X86, including the Linux virtual and physi- cal memory management
enhancements that were used to support the high rate of virtual memory
operations required for sustained pauseless operation. We discuss
updates to the collector’s manage- ment of the heap for efficient
generational collection and provide throughput and pause time data
while running sustained workloads.
